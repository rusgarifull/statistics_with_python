{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats.distributions as dist\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats as sts\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between two proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value_and_t_stat (count1, nobs1, count2, nobs2):\n",
    "    # Estimates of the population proportions\n",
    "    p1 = round(count1 / nobs1, 6)\n",
    "    p2 = round(count2 / nobs2, 6)\n",
    "\n",
    "    # Estimate of the combined population proportion\n",
    "    phat = (count1 + count1) / (nobs1 + nobs2)\n",
    "\n",
    "    # Estimate of the variance of the combined population proportion\n",
    "    va = phat * (1 - phat)\n",
    "\n",
    "    # Estimate of the standard error of the combined population proportion\n",
    "    se = np.sqrt(va * (1 / nobs1 + 1 / nobs2))\n",
    "\n",
    "    # Test statistic and its p-value\n",
    "    test_stat = (p1 - p2) / se\n",
    "    pvalue = 2*dist.norm.cdf(-np.abs(test_stat))\n",
    "\n",
    "    # Print the test statistic its p-value\n",
    "    return test_stat, pvalue\n",
    "\n",
    "\n",
    "def conf_intervals_proportion_diff (count1, nobs1, count2, nobs2, alpha=0.05):\n",
    "    # Estimates of the population proportions\n",
    "    p1 = round(count1 / nobs1 , 6)\n",
    "    p2 = round(count2 / nobs2, 6)\n",
    "    \n",
    "    diff = round(p1 - p2,6)\n",
    "\n",
    "    se_1 = np.sqrt(p1 * (1 - p1)/ nobs1)\n",
    "    se_2 = np.sqrt(p2 * (1 - p2)/ nobs2)\n",
    "    se_diff = np.sqrt(se_1**2 + se_2**2)\n",
    "\n",
    "    # z critical value\n",
    "    confidence = 1 - alpha\n",
    "    z = stats.norm(loc = 0, scale = 1).ppf(confidence + alpha / 2)\n",
    "    \n",
    "    moe = round(z * se_diff,6)\n",
    "    \n",
    "    lcb = diff - moe\n",
    "    ucb = diff + moe\n",
    "    \n",
    "    result_as_string = \"{} += {}\".format(diff,moe)\n",
    "    \n",
    "    return diff, moe, lcb, ucb\n",
    "\n",
    "\n",
    "def conf_intervals_one_proportion(count1, nobs1, alpha=0.05):\n",
    "    \n",
    "    p1 = round(count1 / nobs1, 6)\n",
    "    se = np.sqrt(p1 * (1 - p1)/ nobs1)\n",
    "    \n",
    "    # z critical value\n",
    "    confidence = 1 - alpha\n",
    "    z = stats.norm(loc = 0, scale = 1).ppf(confidence + alpha / 2)\n",
    "    \n",
    "    moe = round(z * se,6)\n",
    "    \n",
    "    return moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input Data\n",
    "\n",
    "# Sample sizes (Visitors)\n",
    "n_1 = 5976004  \n",
    "n_2 = 5972203   \n",
    "\n",
    "# Proportions (Visitors with clicks)\n",
    "clicks_1 = 2001183\n",
    "clicks_2 = 2004354\n",
    "\n",
    "# Confidencce level\n",
    "alpha=0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR_1: 0.33487+=0.000318 ((0.3345522050375604, 0.3351873065156447))\n",
      "CR_2: 0.335614+=0.000318 ((0.33529601643224166, 0.3359316695657058))\n",
      "0.000744\n",
      "0.002222\n"
     ]
    }
   ],
   "source": [
    "# Conversion rate (CR)\n",
    "cr_1 = round(clicks_1/n_1,6)\n",
    "cr_2 = round(clicks_2/n_2,6)\n",
    "cr_diff = round(cr_2-cr_1,6) # abs differnce in ET tool\n",
    "cr_diff_relative = round(cr_diff/cr_1,6) # relative differenc in ET tool\n",
    "\n",
    "# Conf. intervals for each CR\n",
    "moe_1 = conf_intervals_one_proportion(clicks_1, n_1, alpha) \n",
    "moe_2 = conf_intervals_one_proportion(clicks_2, n_2, alpha) \n",
    "\n",
    "# Caclulate conf intervals directly\n",
    "ci_1 = sm.stats.proportion_confint(clicks_1, n_1, alpha)\n",
    "ci_2 = sm.stats.proportion_confint(clicks_2, n_2, alpha)\n",
    "\n",
    "print(\"CR_1: {}+={} ({})\".format(cr_1, moe_1, ci_1))\n",
    "print(\"CR_2: {}+={} ({})\".format(cr_2, moe_2, ci_2))\n",
    "print(cr_diff)\n",
    "print(ci_diff_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00646299278272296\n",
      "0.006446317007577497\n",
      "p-value is small, the difference is stat. significant\n"
     ]
    }
   ],
   "source": [
    "# calculate statistical significance (t_stats and p value) and conf. intervals for the difference\n",
    "\n",
    "# 1st way\n",
    "t_stat, p_value = get_p_value_and_t_stat(clicks_2, n_2, clicks_1 ,n_1)\n",
    "print(p_value) # significance in ET tool\n",
    "\n",
    "# 2nd way\n",
    "# Create populations \n",
    "pop_1 = np.array([1]*clicks_1+[0]*(n_1-clicks_1))\n",
    "pop_2 = np.array([1]*clicks_2+[0]*(n_2-clicks_2))\n",
    "# calulate p_value based on arrays \n",
    "t_stat, p_value = stats.ttest_ind(pop_2,pop_1)\n",
    "print(p_value) # significance in ET tool\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print('p-value is small, the difference is stat. significant')\n",
    "else:\n",
    "    print('p-value is large, the difference is not stat. significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR difference: 0.000744+=0.000535 (0.00020899999999999998, 0.001279)\n",
      "CR difference(relative): 0.002222+=0.001598 (0.000624, 0.003819)\n",
      "using API\n",
      "CR difference: (0.00020873741160846407, 0.0012794365818959554)\n",
      "CR difference(relative): (0.000623,0.003821)\n"
     ]
    }
   ],
   "source": [
    "# Confidence intervals\n",
    "\n",
    "# 1 way\n",
    "\n",
    "# absolute difference\n",
    "diff, moe, lcl, ucl = conf_intervals_proportion_diff(clicks_2, n_2, clicks_1, n_1)\n",
    "print(\"CR difference: {}+={} ({}, {})\".format(diff, moe, lcl, ucl))\n",
    "\n",
    "# relative difference\n",
    "print(\"CR difference(relative): {}+={} ({}, {})\".format(round(diff/cr_1,6), round(moe/cr_1,6), \n",
    "                                                        round(lcl/cr_1,6), round(ucl/cr_1,6))\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "# 2 way\n",
    "      \n",
    "# absolute difference\n",
    "print(\"using API\")\n",
    "ci_diff = sts.proportion.confint_proportions_2indep(clicks_2, n_2, clicks_1, n_1)\n",
    "print(\"CR difference: {}\".format(ci_diff))\n",
    "\n",
    "# relative difference\n",
    "lcl_rel = round(ci_diff[0]/cr_1,6) \n",
    "ucl_rel = round(ci_diff[1]/cr_1,6)\n",
    "print(\"CR difference(relative): ({},{})\".format(lcl_rel,ucl_rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. Is there a library that calculates p_value based on sample size and # of observations for Proportion difference?I.e. Similar to this function - get_p_value_and_t_stat(count1, nobs1, count2, nobs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnings\n",
    "\n",
    "1. Bigger sample size(traffic) -> better (faster to detect significance)\n",
    "2. Higher  proportion levels (or CR) - better (faster) to detect significance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
